{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wu3Iwz4wDAe"
      },
      "source": [
        "경로지정과 csv 읽는 파일만 변경해주면 돼\n",
        "\n",
        "누적 저장 가능\n",
        "\n",
        "200개씩 알아서 끊어서 크롤링해줌\n",
        "\n",
        "크롤링 성공한 가게 수\n",
        "\n",
        "크롤링 실패한 가게 수\n",
        "\n",
        "총 크롤링한 리뷰 개수 마지막에 포함시킴\n",
        "\n",
        "\n",
        "변경해야할 부분을 컨트롤 f 로 검색하면 뭘 변경해야할지 알 수 잇음\n",
        "\n",
        "모르겠으면 물어보셔유"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBBM0vmxgLaf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import re\n",
        "\n",
        "crawl = 400 ## 변경해야할 부분\n",
        "\n",
        "# 브라우저 옵션 설정\n",
        "options = Options()\n",
        "options.add_argument(\"window-size=1920x1080\")\n",
        "service = ChromeService(executable_path=ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=options)\n",
        "\n",
        "# 데이터 불러오기\n",
        "df_filtered = (\n",
        "    pd.read_csv('서울시 휴게음식점 인허가 정보-2.csv')\n",
        "    .query('업태구분명 in [\"다방\", \"커피숍\", \"떡카페\"] and 상세영업상태명 == \"영업\"')\n",
        "    [['사업장명', '도로명주소']]\n",
        "    .fillna({'도로명주소': ''})\n",
        ")\n",
        "\n",
        "df_filtered['도로명주소'] = (\n",
        "    df_filtered['도로명주소']\n",
        "    .apply(lambda x: ' '.join(x.split(',')[0].split()[:4]))\n",
        ")\n",
        "\n",
        "records = df_filtered.to_dict(orient='records')\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "# 누적 저장을 위한 CSV 경로 및 컬럼 정의\n",
        "csv_path = os.path.expanduser('~/Desktop/naver_review.csv')\n",
        "if os.path.exists(csv_path):\n",
        "    df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
        "\n",
        "    if not df.empty:\n",
        "        last_row = df.iloc[-1]  # 마지막 행\n",
        "        total_review = last_row['총 리뷰 개수']\n",
        "        already_crawled =  last_row['최종 크롤링 개수']\n",
        "        print(\"최종 크롤링 개수:\", already_crawled)\n",
        "    else:\n",
        "        print(\"CSV 파일은 있지만 데이터가 없습니다.\")\n",
        "else:\n",
        "    already_crawled = 0 ## 변경해야할 부분\n",
        "    total_review = 1\n",
        "    print(\"CSV 파일이 존재하지 않습니다.\")\n",
        "\n",
        "columns = ['공공데이터 가게명',\n",
        "           '크롤링 가게명',\n",
        "           '카테고리',\n",
        "           '시간',\n",
        "           '평점',\n",
        "           '출처',\n",
        "           'content',\n",
        "           'date',\n",
        "           'revisit',\n",
        "           '방문목적',\n",
        "           '동반자',\n",
        "           '태그',\n",
        "           '선택 수',\n",
        "           '편의시설',\n",
        "           '최종 크롤링 개수',\n",
        "           '총 리뷰 개수']\n",
        "review_data = []\n",
        "success = 0\n",
        "fail = 0\n",
        "review_cnt = 0\n",
        "crawl_end = already_crawled+crawl\n",
        "if crawl_end > 5324: #변경해야할 부분\n",
        "    crawl_end = 5324\n",
        "\n",
        "# 크롤링 시작\n",
        "for row in records[already_crawled:crawl_end]:\n",
        "    restaurant = row['사업장명']\n",
        "    address = row['도로명주소']\n",
        "    driver.get(\"https://m.map.naver.com/#search\")\n",
        "    time.sleep(3)\n",
        "\n",
        "    try:\n",
        "        search_input = driver.find_element(By.XPATH, '//input[contains(@placeholder, \"검색\")]')\n",
        "        search_input.click()\n",
        "        search_input.send_keys(restaurant)\n",
        "        search_input.send_keys(Keys.ENTER)\n",
        "    except Exception as e:\n",
        "        print(f\"❗ 검색창 오류: {e}\")\n",
        "        continue\n",
        "\n",
        "    time.sleep(3)\n",
        "    found_matching_address = False\n",
        "\n",
        "    try:\n",
        "        search_restaurant_list = driver.find_elements(By.XPATH, \"//div[contains(@class, '_item_info_wrap_')]\")\n",
        "        for a in search_restaurant_list:\n",
        "            try:\n",
        "                add_el = a.find_element(By.XPATH, \".//button[contains(@class,'_item_address_')]\")\n",
        "                address_extracted = add_el.text.strip()\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            if address not in address_extracted:\n",
        "                continue\n",
        "\n",
        "            found_matching_address = True\n",
        "\n",
        "            try:\n",
        "                a_href_el = a.find_element(By.XPATH, \".//a[contains(@href,'/place/') and contains(@href,'/home')]\")\n",
        "                a_href = a_href_el.get_attribute(\"href\")\n",
        "            except:\n",
        "                a_href = \"\"\n",
        "\n",
        "            try:\n",
        "                name_el = a.find_element(By.XPATH, \".//strong[contains(@class,'_item_name_')]\")\n",
        "                store_name = name_el.text.strip()\n",
        "            except:\n",
        "                store_name = \"\"\n",
        "\n",
        "            try:\n",
        "                cat_el = a.find_element(By.XPATH, \".//em[contains(@class,'_item_category_')]\")\n",
        "                category = cat_el.text.strip()\n",
        "            except:\n",
        "                category = \"\"\n",
        "\n",
        "            a_href_el.click()\n",
        "            break\n",
        "\n",
        "        if not found_matching_address:\n",
        "            fail=fail+1\n",
        "            # print(f\"❗ {restaurant} - 주소 매칭 실패, 건너뜀\")\n",
        "            continue\n",
        "        success = success+1\n",
        "        time.sleep(3)\n",
        "        # print(store_name)\n",
        "\n",
        "        try:\n",
        "            # XPath로 조건에 맞는 a 태그 선택\n",
        "            button = driver.find_element(By.XPATH, '//a[contains(@class, \"gKP9i RMgN0\") and @aria-expanded=\"false\"]')\n",
        "            button.click()\n",
        "            time.sleep(2)\n",
        "        except Exception as e:\n",
        "            print(f\"❗ 버튼 클릭 실패: {e}\")\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            # rows = driver.find_elements(By.XPATH, '//div[contains(@class, \"w9QyJ\")]')\n",
        "            rows = driver.find_elements(By.XPATH, '//*[@class=\"w9QyJ\"]')\n",
        "            hours_list = []\n",
        "\n",
        "            for row in rows:\n",
        "                # 요일 추출 (없으면 \"매일\")\n",
        "                try:\n",
        "                    day = row.find_element(By.XPATH, './/span[contains(@class, \"i8cJw\")]').text.strip()\n",
        "                except:\n",
        "                    day = \"매일\"\n",
        "\n",
        "                # 시간 추출 (없으면 \"정보 없음\")\n",
        "                time_range_elements = row.find_elements(By.XPATH, './/div[contains(@class, \"H3ua4\")]')\n",
        "                time_range = time_range_elements[0].text.strip() if time_range_elements else \"정보 없음\"\n",
        "\n",
        "                hours_list.append(f\"{day} {time_range}\")\n",
        "\n",
        "            time_combined = \" | \".join(hours_list)\n",
        "            # print(\"🕒 영업시간:\", time_combined)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❗ 영업 시간 전체 추출 실패: {e}\")\n",
        "            time_combined = \"\"\n",
        "            pass\n",
        "        # 정보탭 클릭\n",
        "        try:\n",
        "            information_tab = driver.find_element(By.XPATH, \"//a[contains(@href,'/information')]\")\n",
        "            information_tab.click()\n",
        "        except Exception as e:\n",
        "            print(f\"❗ 정보 탭 오류: {e}\")\n",
        "            pass\n",
        "        time.sleep(3)\n",
        "        # place_section_content 하위의 owG4q 요소들 선택\n",
        "        try:\n",
        "            elements = driver.find_elements(By.XPATH, '//ul[contains(@class, \"JU0iX\")]//div[@class=\"owG4q\"]')\n",
        "            facility_data = [el.text.strip() for el in elements if el.text.strip()]\n",
        "        except:\n",
        "            facility_data = []\n",
        "            pass\n",
        "        # print(facility_data)\n",
        "        time.sleep(3)\n",
        "\n",
        "        try:\n",
        "            review_tab = driver.find_element(By.XPATH, \"//a[contains(@href,'/review')]\")\n",
        "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", review_tab)\n",
        "            time.sleep(1)\n",
        "            driver.execute_script(\"arguments[0].click();\", review_tab)\n",
        "            time.sleep(2)\n",
        "            # print(\"✅ 리뷰 탭 클릭 성공\")\n",
        "        except Exception as e:\n",
        "            print(f\"❗ 리뷰 탭 클릭 실패: {e}\")\n",
        "            continue\n",
        "\n",
        "        time.sleep(3)\n",
        "\n",
        "        try:\n",
        "            rating = driver.find_element(By.XPATH, \"//span[contains(@class,'PXMot') or contains(@class,'_1Y6hi')]\").text.strip()\n",
        "        except:\n",
        "            rating = \"\"\n",
        "\n",
        "        tag_data = []\n",
        "        # 태그 더보기 반복 클릭\n",
        "        while True:\n",
        "            try:\n",
        "                more_button = driver.find_element(By.XPATH, '//span[contains(@class, \"YqDZw\")]')\n",
        "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
        "                time.sleep(1)\n",
        "            except:\n",
        "                break\n",
        "\n",
        "        # 태그 요소 수집\n",
        "        tag_elements = driver.find_elements(By.XPATH, '//span[contains(@class, \"t3JSf\")]')\n",
        "        for tag in tag_elements:\n",
        "            try:\n",
        "                tag_name = tag.text.strip()\n",
        "                tag_count_element = tag.find_element(By.XPATH, './following-sibling::span')\n",
        "                tag_count = int(re.sub(r'[^0-9]', '', tag_count_element.text.strip()))\n",
        "                tag_data.append((tag_name, tag_count))\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        tag_data = sorted(tag_data, key=lambda x: x[1], reverse=True)  # 전체 태그 수집\n",
        "        # 리뷰 수집\n",
        "        all_reviews = []\n",
        "        review_limits = {\"추천\": 5, \"최신\": 5}\n",
        "\n",
        "        for source_label in [\"추천\", \"최신\"]:\n",
        "            if source_label == \"최신\":\n",
        "                try:\n",
        "                    latest_button = driver.find_element(By.XPATH, \"//a[@role='option' and @aria-selected='false']\")\n",
        "                    latest_button.click()\n",
        "                    time.sleep(5)\n",
        "                except:\n",
        "                    print(f\"❗ 최신순 버튼 클릭 오류\")\n",
        "                    continue\n",
        "\n",
        "            reviews = driver.find_elements(By.XPATH, '//li[contains(@class,\"place_apply_pui\")]')\n",
        "            count = 0\n",
        "\n",
        "            for r in reviews[:review_limits[source_label]]:\n",
        "                try:\n",
        "                    content = r.find_element(By.XPATH, './/div[contains(@class,\"pui__vn15t2\")]').text.strip()\n",
        "                    date = r.find_element(By.XPATH, './/span[contains(@class,\"pui__gfuUIT\")]/time').text.strip()\n",
        "\n",
        "                    revisit_elements = r.find_elements(By.XPATH, './/span[contains(@class,\"pui__gfuUIT\")]')\n",
        "                    revisit = revisit_elements[1].text.strip() if len(revisit_elements) > 1 else ''\n",
        "                    if revisit:\n",
        "                        revisit = int(revisit.replace(\",\", \"\")[:-5])\n",
        "\n",
        "                    try:\n",
        "                        tag_expand_button = r.find_element(By.XPATH, './/a[contains(@class,\"pui__jhpEyP\")]')\n",
        "                        driver.execute_script(\"arguments[0].click();\", tag_expand_button)\n",
        "                        time.sleep(3)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                    try:\n",
        "                        div = r.find_element(By.XPATH, './/div[contains(@class, \"pui__-0Ter1\")]')\n",
        "                        spans = div.find_elements(By.TAG_NAME, 'span')\n",
        "                        span_texts = [span.text.strip() for span in spans]\n",
        "                        visit_tag = span_texts[3].strip() if len(span_texts) >= 3 else \"태그 없음\"\n",
        "                        mate_tag = span_texts[4].strip() if len(span_texts) >= 4 else \"태그 없음\"\n",
        "                    except:\n",
        "                        visit_tag = \"태그 없음\"\n",
        "                        mate_tag = \"태그 없음\"\n",
        "\n",
        "                    all_reviews.append([\n",
        "                        restaurant, store_name, category, time_combined, rating, source_label,\n",
        "                        content, date, revisit,  visit_tag, mate_tag, already_crawled+crawl,total_review+review_cnt\n",
        "                    ])\n",
        "                    count += 1\n",
        "                    review_cnt = review_cnt+1\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        max_len = max(len(all_reviews), len(tag_data), len(facility_data))\n",
        "        # ✅ 태그가 10개 미만일 경우 빈 값으로 채우기\n",
        "        tag_data += [(\"\", \"\")] * (max_len - len(tag_data))\n",
        "        facility_data += [\"\"] * (max_len - len(facility_data))\n",
        "        all_reviews += [\n",
        "            [restaurant, store_name, category, time_combined, rating, '', '', '', '', '', '', already_crawled + crawl, total_review + review_cnt]\n",
        "        ] * (max_len - len(all_reviews))\n",
        "\n",
        "        for i in range(max_len):\n",
        "            review = all_reviews[i]\n",
        "            tag_name, tag_count = tag_data[i]\n",
        "            facility = facility_data[i]\n",
        "\n",
        "            review_data.append([\n",
        "                *review[:11],      # 기본 리뷰 정보 (0~10)\n",
        "                tag_name, tag_count,\n",
        "                facility,          # 편의시설\n",
        "                review[11], review[12]  # 크롤링 수, 리뷰 수\n",
        "            ])\n",
        "    except Exception as e:\n",
        "        print(f\"❗ 가게 검색 중 오류: {e}\")\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "# 누적 저장 처리\n",
        "df_new = pd.DataFrame(review_data, columns=columns)\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    df_old = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
        "    df_combined = pd.concat([df_old, df_new], ignore_index=True)\n",
        "else:\n",
        "    df_combined = df_new\n",
        "\n",
        "# 저장  ## 변경해야할 부분\n",
        "df_combined.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"크롤링 성공 개수 : {success}, 크롤링 실패 개수 : {fail}, 총 수집한 리뷰 개수 : {review_cnt}\")\n",
        "print(f\"📁 리뷰 데이터를 누적 저장했습니다: {csv_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
